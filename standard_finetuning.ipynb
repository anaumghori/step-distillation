{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv56r0YdbSqrh+Q8x99q/V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install and Imports**"
      ],
      "metadata": {
        "id": "d63XB0FPNktp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA7FpPMd8d8x",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "xIMUk3Qoh3py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load dataset and Create splits**\n",
        "### Sample 10% of training data for validation set as done in the original paper"
      ],
      "metadata": {
        "id": "kvsiPrMjNrOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"Salesforce/cos_e\", \"v1.11\", split={\"train\": \"train\", \"test\": \"validation\"})\n",
        "\n",
        "def modify_example(example):\n",
        "    choice_labels = ['(a)', '(b)', '(c)', '(d)', '(e)']\n",
        "    formatted_choices = \"\\n\".join([f\"{choice_labels[i]} {choice}\" for i, choice in enumerate(example[\"choices\"])])\n",
        "    input_text = f\"{example['question']}\\nAnswer Choices:\\n{formatted_choices}\"\n",
        "    return {\n",
        "        \"input\": input_text,\n",
        "        \"label\": example[\"answer\"]\n",
        "    }\n",
        "\n",
        "dataset = {split: data.map(modify_example, remove_columns=['id', 'question', 'choices', 'answer', 'abstractive_explanation', 'extractive_explanation']) for split, data in ds.items()}\n",
        "\n",
        "# Create validation split from original training data\n",
        "val_dataset = dataset[\"train\"]\n",
        "val_size = int(0.1 * len(val_dataset))  # 10% for validation\n",
        "train_size = len(val_dataset) - val_size\n",
        "\n",
        "# Create the split\n",
        "train_set, val_set = random_split(\n",
        "    val_dataset,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")"
      ],
      "metadata": {
        "id": "4gtH43y6in_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_splits = {'train': train_set, 'val': val_set, 'test': dataset['test']}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    print(f\"Length of {split_name}_set:\", len(split_data))\n",
        "    print(f\"First element of {split_name}_set:\", split_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF8zYCvyr4n7",
        "outputId": "794c4db3-93dd-43d4-99b7-1679d84dab8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train_set: 8767\n",
            "First element of train_set: {'input': 'Where might someone keep personal soap?\\nAnswer Choices:\\n(a) birthday party\\n(b) supermarket\\n(c) own home\\n(d) jail\\n(e) cabinet', 'label': 'own home'}\n",
            "Length of val_set: 974\n",
            "First element of val_set: {'input': 'What do you have to do to learn to play violin?\\nAnswer Choices:\\n(a) tune\\n(b) practise\\n(c) relaxing\\n(d) ask questions\\n(e) take lessons', 'label': 'take lessons'}\n",
            "Length of test_set: 1221\n",
            "First element of test_set: {'input': 'A beaver is know for building prowess, their supplies come from where?\\nAnswer Choices:\\n(a) british columbia\\n(b) body of water\\n(c) wooded area\\n(d) pay debts\\n(e) zoo', 'label': 'wooded area'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Dataset Class**"
      ],
      "metadata": {
        "id": "Pvl0If-oN14i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class T5FineTuningDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_length=128):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.dataset[idx]\n",
        "\n",
        "        # Tokenize inputs\n",
        "        input_encoding = self.tokenizer(\n",
        "            example['input'],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Tokenize labels\n",
        "        label_encoding = self.tokenizer(\n",
        "            example['label'],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Replace padding token ID with -100\n",
        "        labels = label_encoding.input_ids.clone()\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding.input_ids.squeeze(),\n",
        "            'attention_mask': input_encoding.attention_mask.squeeze(),\n",
        "            'labels': labels.squeeze()\n",
        "        }"
      ],
      "metadata": {
        "id": "cUXNjiwvTl-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Validation Function**"
      ],
      "metadata": {
        "id": "IMDd_k0TY5wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    return total_val_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "0XDmAjjqY_T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the model**"
      ],
      "metadata": {
        "id": "asoZfor-jj_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_set, val_set, model_name=\"google-t5/t5-small\", max_length=1024,\n",
        "                batch_size=16, num_epochs=25, learning_rate=3e-5, weight_decay=0.01):\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    device = \"cuda\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare training and validation datasets\n",
        "    train_dataset = T5FineTuningDataset(train_set, tokenizer, max_length)\n",
        "    val_dataset = T5FineTuningDataset(val_set, tokenizer, max_length)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    total_steps = len(train_loader) * num_epochs\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Initialize variables to track best model\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            # Move batch to device\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} - Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        print(\"Running validation...\")\n",
        "        val_loss = validate_model(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch+1} - Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with validation loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Load best model for final evaluation\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "EyJ-VIKwjm0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = train_model(train_set, val_set)"
      ],
      "metadata": {
        "id": "KMwu-QGTm1l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the model**"
      ],
      "metadata": {
        "id": "eVYDg9Cy4I7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, tokenizer, test_dataset, max_length=1024, batch_size=16):\n",
        "    device = \"cuda\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare test dataset\n",
        "    test_dataset_processed = T5FineTuningDataset(test_dataset, tokenizer, max_length)\n",
        "    test_loader = DataLoader(test_dataset_processed, batch_size=batch_size)\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    print(\"Starting evaluation...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Generate predictions\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=max_length\n",
        "            )\n",
        "\n",
        "            # Decode predictions and references\n",
        "            preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "            # Replace -100 with pad token id first\n",
        "            label_ids = labels.clone()\n",
        "            label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "            refs = [tokenizer.decode(label, skip_special_tokens=True) for label in label_ids]\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            references.extend(refs)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(references, predictions) * 100\n",
        "    return accuracy, predictions, references"
      ],
      "metadata": {
        "id": "lpJjTuo-4IKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, predictions, references = evaluate_model(model, tokenizer, dataset[\"test\"])"
      ],
      "metadata": {
        "id": "isExwODz4ZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ],
      "metadata": {
        "id": "Kq4qUbcD4wPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_evaluation_results(accuracy, predictions, references, num_samples=5):\n",
        "\n",
        "    print(f\"Final Evaluation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Display some examples\n",
        "    print(\"\\nSample predictions:\")\n",
        "    for i in range(min(num_samples, len(predictions))):\n",
        "        print(f\"Reference: {references[i]}\")\n",
        "        print(f\"Prediction: {predictions[i]}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "SR5XgrGB4yF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_evaluation_results(accuracy, predictions, references, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d82a8be-5ea1-430f-b518-1b2ad8f88d4e",
        "id": "HZwkEEwwuQNt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation Accuracy: 41.20%\n",
            "\n",
            "Sample predictions:\n",
            "Reference: wooded area\n",
            "Prediction: wooded area\n",
            "--------------------------------------------------\n",
            "Reference: go downtown\n",
            "Prediction: east\n",
            "--------------------------------------------------\n",
            "Reference: play tag\n",
            "Prediction: play tag\n",
            "--------------------------------------------------\n",
            "Reference: great outdoors\n",
            "Prediction: fairytale\n",
            "--------------------------------------------------\n",
            "Reference: appliance store\n",
            "Prediction: appliance store\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}